{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle猫狗大战.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MI2x_BFn58Z",
        "colab_type": "text"
      },
      "source": [
        "## 卷积神经网络：猫狗识别"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv194rEYoC42",
        "colab_type": "text"
      },
      "source": [
        "**目录**\n",
        " -  第一步：导入数据集\n",
        " -  第二步：数据预处理\n",
        " -  第三步：迁移学习\n",
        " -  第四步：模型保存\n",
        " -  第五步：模型融合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGNE9199oyG-",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### 第一步：导入数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sULwGYgAsA2T",
        "colab_type": "text"
      },
      "source": [
        "kaggle猫狗大战数据集地址:[kaggle](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUqNau6fn-c_",
        "colab_type": "code",
        "outputId": "8ba44488-31f2-41f1-e5c2-731b0dd2f4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# 将kaggle的数据集直接下载到codelab中\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"codingchaozhang\",\"key\":\"9bc00f2d33aa7fd38f0a3e455905210a\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading test.zip to /content\n",
            " 98% 265M/271M [00:02<00:00, 125MB/s]\n",
            "100% 271M/271M [00:02<00:00, 115MB/s]\n",
            "Downloading train.zip to /content\n",
            " 99% 536M/544M [00:03<00:00, 192MB/s]\n",
            "100% 544M/544M [00:03<00:00, 163MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/111k [00:00<?, ?B/s]\n",
            "100% 111k/111k [00:00<00:00, 116MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXT5pPNnqY7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将文件解压\n",
        "! unzip ./train.zip \n",
        "! unzip ./test.zip  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ITRs7YtnWm",
        "colab_type": "text"
      },
      "source": [
        "总之，训练集有25000张图片，猫狗各占一半。测试集有12500张，没有标定是猫还是狗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkbQSdgltKol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls ./train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO_R54eiuoua",
        "colab_type": "text"
      },
      "source": [
        "可以看出图片名是以`type.number.jpg`格式命名的"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tZI2wNtufPW",
        "colab_type": "code",
        "outputId": "21f2dffd-64fb-4b1d-c669-1cb731b0e9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 导入开发需要的库\n",
        "import keras\n",
        "import os\n",
        "import shutil\n",
        "import threading\n",
        "import numpy as np\n",
        "import cv2\n",
        "import h5py\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "\n",
        "from keras.applications import *\n",
        "from keras.preprocessing import *\n",
        "from keras.preprocessing.image import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaBI561bvPEi",
        "colab_type": "text"
      },
      "source": [
        "### 第二步：数据预处理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHTDPjox3-ZX",
        "colab_type": "text"
      },
      "source": [
        "**加载数据**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XFpysDHu_M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(load_type=\"train\"):\n",
        "    path = None\n",
        "    n = 25000\n",
        "    if load_type==\"train\":\n",
        "        imgs = []\n",
        "        labels = []\n",
        "        \n",
        "        path = \"./train/\"\n",
        "        img_names = os.listdir(path)\n",
        "        \n",
        "        for name in img_names:\n",
        "            imgs.append(\"train/\"+name)\n",
        "            labels.append([0] if name[:3] == \"cat\" else [1])\n",
        "            \n",
        "        train_img_names,valid_img_names,train_labels,valid_labels = train_test_split(imgs,labels,test_size=0.2,random_state=42)\n",
        "        return train_img_names,valid_img_names,train_labels,valid_labels\n",
        "    else:\n",
        "        # test,don`t have the labels\n",
        "        path = \"./test\"\n",
        "        img_names = os.listdir(path)\n",
        "        imgs = []\n",
        "        for img in img_names:\n",
        "            imgs.append(img)\n",
        "                \n",
        "        return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1yGKLuQ6ONK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img_names,valid_img_names,train_labels,valid_labels = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnKB0PSx6V-9",
        "colab_type": "code",
        "outputId": "460b7136-ce58-4223-842a-2c04945ceb78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(train_img_names[:5])\n",
        "print(train_labels[:5])\n",
        "print(len(train_img_names)+len(valid_img_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['train/dog.12105.jpg', 'train/cat.10129.jpg', 'train/dog.11009.jpg', 'train/dog.9346.jpg', 'train/dog.1599.jpg']\n",
            "[[1], [0], [1], [1], [1]]\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuYrRpVx8QOg",
        "colab_type": "text"
      },
      "source": [
        "数据准备之后，接下来就是准备开始训练:\n",
        "\n",
        "`预先步骤`：\n",
        "  - 分别初始化三个Generator(train,valid,test)\n",
        "  - 加载预训练网络\n",
        "  - 进行微调（迁移学习）\n",
        "  - 调参"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeozeKI-8UpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义keras的generator方法\n",
        "# custom keras generator\n",
        "class MOGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, data, n, des_size=(224, 224), means=None, stds=None,\n",
        "                 is_directory=True, batch_size=32, shuffle=True, seed=0):\n",
        "        '''\n",
        "        data: tuple of (x,y)\n",
        "        n: data size\n",
        "        des_size: standard size\n",
        "        means: the dataset mean of RGB,default is imagenet means [103.939, 116.779, 123.68]\n",
        "        batch_size: default is 32\n",
        "        shuffle: random the data,default is True\n",
        "        '''\n",
        "        self.x = np.array(data[0])\n",
        "        if len(data) >= 2:\n",
        "            self.y = np.array(data[1])\n",
        "        else:\n",
        "            self.y = None\n",
        "        self.n = n\n",
        "        self.des_size = des_size\n",
        "        self.is_directory = is_directory\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.lock = threading.Lock()\n",
        "        self.index_array = self._set_index_array()\n",
        "        self.means = means\n",
        "        self.stds = stds\n",
        "\n",
        "    def reset_index(self):\n",
        "        self.batch_index = 0\n",
        "\n",
        "    def _set_index_array(self):\n",
        "        self.index_array = np.arange(self.n)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.index_array)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # 重置索引数组\n",
        "        self._set_index_array()\n",
        "\n",
        "    def __len__(self):\n",
        "        # 计算batch的总数量\n",
        "        return int(np.ceil(self.n / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.index_array is None:\n",
        "            self._set_index_array()\n",
        "        index_array = self.index_array[self.batch_size * idx:\n",
        "                                       self.batch_size * (idx + 1)]\n",
        "        return self._data_generate(index_array)\n",
        "\n",
        "    def _data_generate(self, index_array):\n",
        "        # read from path\n",
        "        # request the memory\n",
        "        imgs = np.zeros((len(index_array), self.des_size[0], self.des_size[1], 3), dtype=np.uint8)\n",
        "        # read the data\n",
        "        if self.is_directory:\n",
        "            img_names = self.x[index_array]\n",
        "            for name_index in range(len(img_names)): \n",
        "                img = cv2.imread(img_names[name_index])\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, self.des_size)\n",
        "                    imgs[name_index] = img\n",
        "        else:\n",
        "            for i in range(len(index_array)):\n",
        "                img = self.x[index_array[i]]\n",
        "                img = cv2.resize(img, self.des_size)\n",
        "                imgs[i] = img\n",
        "        if self.y is not None:\n",
        "            labels = self.y[index_array]\n",
        "        if labels is None:\n",
        "            return imgs\n",
        "        else:\n",
        "            return imgs, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9JfIUwT9r4A",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "我们会使用3个模型去迁移学习，它们的对输入图片的大小要求不同，所以我们会初始化不同大小的 Generator\n",
        "\n",
        "|  | 大小 |\n",
        "| :--: | :--: |\n",
        "| Xception | (299, 299, 3) |\n",
        "| Inceptionv3 | (299, 299, 3) |\n",
        "| Resnet50 | (224, 224, 3) |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5Q780uC6aTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_img_names,valid_img_names,train_labels,valid_labels = load_data()\n",
        "\n",
        "test_img_names = load_data(load_type=\"test\")\n",
        "\n",
        "train_generator_224 = MOGenerator((train_img_names,train_labels), len(train_img_names), des_size=(224,224),\n",
        "                                  batch_size=batch_size, shuffle=True)\n",
        "\n",
        "train_generator_299 = MOGenerator((train_img_names,train_labels), len(train_img_names), des_size=(299,299),\n",
        "                                  batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_generator_299 = MOGenerator((valid_img_names,valid_labels), len(valid_img_names), des_size=(299,299),\n",
        "                                  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "valid_generator_224 = MOGenerator((valid_img_names,valid_labels), len(valid_img_names), des_size=(224,224),\n",
        "                                  batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_generator_299 = MOGenerator((test_img_names), len(test_img_names), des_size=(299,299),\n",
        "                                  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_generator_224 = MOGenerator((test_img_names), len(test_img_names), des_size=(224,224),\n",
        "                                  batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjKFG5ziGlAG",
        "colab_type": "text"
      },
      "source": [
        "### 第三步:迁移学习"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ4JkEcDGpkA",
        "colab_type": "text"
      },
      "source": [
        "**我们要完成三个模型的迁移(Resnet,Inception,Xception)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXRpaQviGz63",
        "colab_type": "text"
      },
      "source": [
        "**下面开始第一个模型的迁移(Resnet)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-JbmevC6_B9",
        "colab_type": "code",
        "outputId": "85cb8173-7886-4a27-9c5f-aa79828979c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# 加载Resnet50网络, Include_top: 是否包含卷积之后的全连接层.\n",
        "base_model = ResNet50(input_tensor=Lambda(resnet50.preprocess_input)(Input(shape=(224,224,3))), \n",
        "                      weights=\"imagenet\", include_top=False)\n",
        "# 遍历所有层, 将预训练模型的卷积层设置为不可训练, 这样它们的参数就不会被改变了.\n",
        "for layers in base_model.layers:\n",
        "    layers.trainable = False\n",
        "\n",
        "# 重新设置输出层, 我们的类别是两类, 只需要一个神经元即可.\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# 实例化模型\n",
        "model = Model(base_model.input, x)\n",
        "\n",
        "# 设置优化器, 损失函数, 展示参数信息\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 开始训练, 通过设置迭代器模式\n",
        "model.fit_generator(train_generator_224,len(train_img_names)//batch_size,epochs=5,\n",
        "                    validation_data=valid_generator_224,validation_steps=len(valid_img_names)//batch_size,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 101s 162ms/step - loss: 0.1142 - acc: 0.9540 - val_loss: 0.0467 - val_acc: 0.9840\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 97s 155ms/step - loss: 0.0671 - acc: 0.9747 - val_loss: 0.0397 - val_acc: 0.9873\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 98s 156ms/step - loss: 0.0633 - acc: 0.9752 - val_loss: 0.0371 - val_acc: 0.9875\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 98s 157ms/step - loss: 0.0607 - acc: 0.9773 - val_loss: 0.0479 - val_acc: 0.9847\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 98s 157ms/step - loss: 0.0582 - acc: 0.9769 - val_loss: 0.0403 - val_acc: 0.9873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c15a270f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2R0cSsPJJxF",
        "colab_type": "text"
      },
      "source": [
        "**实现Inception模型的迁移**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jixxUKHBHN3g",
        "colab_type": "code",
        "outputId": "a292a5a9-8662-4b02-d697-4472b1fe3faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "## inception\n",
        "inception = inception_v3.InceptionV3(include_top=False,\n",
        "        weights=\"imagenet\",input_tensor=Lambda(inception_v3.preprocess_input)(Input(shape=(299,299,3))),pooling=\"avg\")\n",
        "output = inception.output\n",
        "\n",
        "output = Dropout(0.25)(output)\n",
        "\n",
        "prediction = Dense(1,activation=\"sigmoid\")(output)\n",
        "\n",
        "inception_model = Model(inputs=inception.input,outputs=prediction)\n",
        "\n",
        "for layer in inception.layers: #[:-res_global_pool_index]\n",
        "    layer.trainable = False\n",
        "\n",
        "inception_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "inception_model.fit_generator(train_generator_299,(len(train_img_names) + batch_size - 1)//batch_size,epochs=5,\n",
        "                       validation_data=valid_generator_299,validation_steps=len(valid_img_names)//batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0812 06:20:46.242835 139830584244096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 125s 200ms/step - loss: 0.1636 - acc: 0.9425 - val_loss: 0.0436 - val_acc: 0.9894\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.0878 - acc: 0.9687 - val_loss: 0.0647 - val_acc: 0.9817\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 118s 188ms/step - loss: 0.0818 - acc: 0.9692 - val_loss: 0.0571 - val_acc: 0.9851\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 118s 188ms/step - loss: 0.0756 - acc: 0.9715 - val_loss: 0.0531 - val_acc: 0.9863\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.0780 - acc: 0.9715 - val_loss: 0.0611 - val_acc: 0.9833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29eef91278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeg4yAieJdi9",
        "colab_type": "text"
      },
      "source": [
        "**实现XCeption的迁移学习**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnxnOsDbJb4Y",
        "colab_type": "code",
        "outputId": "53a8a9fb-4d60-49d4-d586-e6e36c58da2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "## xception\n",
        "xcep = Xception(include_top=False, weights=\"imagenet\", \n",
        "                input_tensor=Lambda(xception.preprocess_input)(Input(shape=(299,299,3))),pooling=\"avg\")\n",
        "output = xcep.output\n",
        "\n",
        "output = Dropout(0.25)(output)\n",
        "\n",
        "prediction = Dense(1,activation=\"sigmoid\")(output)\n",
        "\n",
        "xcep_model = Model(inputs=xcep.input,outputs=prediction)\n",
        "\n",
        "for layer in xcep.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "xcep_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "xcep_model.fit_generator(train_generator_299,(len(train_img_names) + batch_size - 1)//batch_size,epochs=5,\n",
        "                       validation_data=valid_generator_299,validation_steps=len(valid_img_names)//batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 280s 447ms/step - loss: 0.1085 - acc: 0.9721 - val_loss: 0.0816 - val_acc: 0.9796\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 274s 439ms/step - loss: 0.0508 - acc: 0.9847 - val_loss: 0.0775 - val_acc: 0.9783\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 275s 440ms/step - loss: 0.0452 - acc: 0.9851 - val_loss: 0.0530 - val_acc: 0.9869\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 275s 440ms/step - loss: 0.0392 - acc: 0.9868 - val_loss: 0.0516 - val_acc: 0.9871\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 274s 438ms/step - loss: 0.0411 - acc: 0.9857 - val_loss: 0.0785 - val_acc: 0.9775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29ebf4d668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUW3hJ7MQgtE",
        "colab_type": "text"
      },
      "source": [
        "### 第四步：模型保存"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqarugi4Qu5H",
        "colab_type": "text"
      },
      "source": [
        "**训练完成后，需要将模型保存，方便下次调用和二次训练**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M4UivndP8SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"resnet.h5\")\n",
        "model.save_weights(\"xcep.h5\")\n",
        "model.save_weights(\"incep.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpDAG6VtSz1y",
        "colab_type": "text"
      },
      "source": [
        "### 第五步:模型融合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQf8IyfaS3KY",
        "colab_type": "text"
      },
      "source": [
        "**导出特征向量**\n",
        "\n",
        "由于数据集的文件名是`type.num.jpg`这样的方式命名的，但是使用keras的ImageDataGenerator需要将不同种类的图片分在不同的文件中，因此我们需要对数据集进行处理。\n",
        "\n",
        "这里采取的思路是创建符号链接，这样的好处是不用复制一遍图片，占用不必要的空间。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwMWwBJmPyW4",
        "colab_type": "code",
        "outputId": "9215c576-36cd-4e6a-a376-c9e3419efd03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from keras.preprocessing.image import *\n",
        "\n",
        "# 获取所有训练集的图片名\n",
        "train_filenames = os.listdir(\"train\")\n",
        "test_filenames = os.listdir(\"test\")\n",
        "\n",
        "# 文件名是特殊命名形式的, 所以直接获取分类后的文件\n",
        "train_cat = list(filter(lambda x:x[:3] == 'cat', train_filenames))\n",
        "train_dog = list(filter(lambda x:x[:3] == 'dog', train_filenames))\n",
        "def rmrf_mkdir(dirname):\n",
        "    if os.path.exists(dirname):\n",
        "        shutil.rmtree(dirname)\n",
        "    os.mkdir(dirname)\n",
        "\n",
        "# 创建目录\n",
        "rmrf_mkdir('train2')\n",
        "os.mkdir('train2/cat')\n",
        "os.mkdir('train2/dog')\n",
        "\n",
        "rmrf_mkdir('valid2')\n",
        "os.mkdir('valid2/cat')\n",
        "os.mkdir('valid2/dog')\n",
        "\n",
        "rmrf_mkdir('test2')\n",
        "os.mkdir(\"test2/test\")\n",
        "for filename in test_filenames:\n",
        "  # 建立软链（不会从创建文件, 有点类似快捷方式）\n",
        "  os.symlink(\"/content/test/\"+filename, \"/content/test2/test/\"+filename)\n",
        "\n",
        "for filename in train_cat[:-2500]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/train2/cat/\"+filename)\n",
        "\n",
        "for filename in train_dog[:-2500]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/train2/dog/\"+filename)\n",
        "\n",
        "for filename in train_cat[-2500:]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/valid2/cat/\"+filename)\n",
        "    \n",
        "for filename in train_dog[-2500:]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/valid2/dog/\"+filename)\n",
        "    \n",
        "# 使用Keras默认的生成器, 因为我们已经生成对应的目录了\n",
        "# 224 是 resnet的处理方式, 299是xception, inception的处理大小\n",
        "gen = ImageDataGenerator()\n",
        "\n",
        "train_generator_224 = gen.flow_from_directory(\"train2\", (224,224), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "valid_generator_224 = gen.flow_from_directory(\"valid2\", (224,224), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "test_generator_224 = gen.flow_from_directory(\"test2\", (224,224), shuffle=False, \n",
        "                                             batch_size=batch_size, class_mode=None)\n",
        "\n",
        "train_generator_299 = gen.flow_from_directory(\"train2\", (299,299), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "valid_generator_299 = gen.flow_from_directory(\"valid2\", (299,299), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "test_generator_299 = gen.flow_from_directory(\"test2\", (299,299), shuffle=False, \n",
        "                                             batch_size=batch_size, class_mode=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n",
            "Found 12500 images belonging to 1 classes.\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n",
            "Found 12500 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w3wKzdza6vR",
        "colab_type": "text"
      },
      "source": [
        "**保存特征向量到本地**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M1lDqwgXYUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "\n",
        "# 特征向量的保存方法\n",
        "def write_feature(model_name,model,train_generator,train_labels,valid_generator,valid_labels,test_generator,batch_size=32):\n",
        "    # 通过模型名字来加载不同的权重\n",
        "    if model_name == 'resnet_feature':\n",
        "        model.load_weights('resnet.h5',by_name=True)\n",
        "    elif model_name == 'inception_feature':\n",
        "        model.load_weights('incep.h5',by_name=True)\n",
        "    else:\n",
        "        model.load_weights('xcep.h5',by_name=True)\n",
        "    # 转换为numpy数组\n",
        "    train_labels = np.array(train_labels)\n",
        "    valid_labels = np.array(valid_labels)\n",
        "    # 直接进行输出, 得到特征向量\n",
        "    train_feature = model.predict_generator(train_generator,int(np.ceil(train_generator.samples/batch_size)),verbose=1)\n",
        "    valid_feature = model.predict_generator(valid_generator,int(np.ceil(valid_generator.samples/batch_size)),verbose=1)\n",
        "    test_feature  = model.predict_generator(test_generator,int(np.ceil(test_generator.samples/batch_size)),verbose=1)\n",
        "    print(\"train_feature.shape:\",train_feature.shape)\n",
        "    print(\"valid_feature.shape:\",valid_feature.shape)\n",
        "    # 保存到本地\n",
        "    with h5py.File(model_name+'.h5','w') as file:\n",
        "        file.create_dataset(\"train\",data=train_feature,dtype=\"float32\")\n",
        "        file.create_dataset('trian_labels',data=np.array(train_generator.classes),dtype=\"uint8\")\n",
        "        file.create_dataset(\"valid\",data=valid_feature,dtype=\"float32\")\n",
        "        file.create_dataset(\"valid_labels\",data=np.array(valid_generator.classes),dtype=\"uint8\")\n",
        "        file.create_dataset(\"test\",data=test_feature,dtype=\"float32\")\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4OLwEjz0N4x",
        "colab_type": "code",
        "outputId": "5cef2efb-a65c-4850-9be7-4fdeaed7a7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# resnet50\n",
        "write_feature('resnet_feature',Model(inputs=model.input,outputs=model.layers[-3].output),\n",
        "              train_generator_224,train_labels,valid_generator_224,valid_labels,test_generator_224)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 85s 136ms/step\n",
            "157/157 [==============================] - 21s 132ms/step\n",
            "391/391 [==============================] - 53s 136ms/step\n",
            "train_feature.shape: (20000, 2048)\n",
            "valid_feature.shape: (5000, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx72rllcYQbA",
        "colab_type": "code",
        "outputId": "9ad29eb7-2abf-43d1-fb77-3ba7d5392a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# inception\n",
        "write_feature('inception_feature',Model(inputs=inception_model.input,outputs=inception_model.layers[-3].output),\n",
        "              train_generator_299,train_labels, valid_generator_299,valid_labels,test_generator_299)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 96s 154ms/step\n",
            "157/157 [==============================] - 24s 152ms/step\n",
            "391/391 [==============================] - 60s 155ms/step\n",
            "train_feature.shape: (20000, 2048)\n",
            "valid_feature.shape: (5000, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5CmvGADb3Qr",
        "colab_type": "code",
        "outputId": "3dc395eb-1277-491d-9fd2-d15441cd0904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# xception\n",
        "write_feature('xception_feature',Model(inputs=xcep_model.input,outputs=xcep_model.layers[-3].output),\n",
        "              train_generator_299,train_labels,valid_generator_299,valid_labels,test_generator_299)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 228s 364ms/step\n",
            "157/157 [==============================] - 57s 360ms/step\n",
            "391/391 [==============================] - 142s 364ms/step\n",
            "train_feature.shape: (20000, 2048)\n",
            "valid_feature.shape: (5000, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JEpGuI3S_9G",
        "colab_type": "text"
      },
      "source": [
        "**搭建融合的模型**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D11xbW9zx5WG",
        "colab_type": "code",
        "outputId": "68af21bb-9b7a-4136-debf-8d9092a447c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "feature_files = ['resnet_feature.h5','inception_feature.h5','xception_feature.h5']\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_valid = []\n",
        "y_valid = []\n",
        "X_test = []\n",
        "\n",
        "for file_name in feature_files:\n",
        "    with h5py.File(file_name, 'r') as h:\n",
        "        X_train.append(np.array(h['train']))\n",
        "        X_valid.append(np.array(h['valid']))\n",
        "        X_test.append(np.array(h['test']))\n",
        "        y_train = np.array(h['trian_labels'])\n",
        "        y_valid = np.array(h['valid_labels'])\n",
        "        print(np.array(h['train']).shape,np.array(h['valid']).shape,np.array(h['test']).shape)\n",
        "\n",
        "X_train = np.concatenate(X_train, axis=1)\n",
        "X_valid = np.concatenate(X_valid, axis=1)\n",
        "X_test = np.concatenate(X_test, axis=1)\n",
        "\n",
        "print(\"last:\",X_train.shape,X_valid.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 2048) (5000, 2048) (12500, 2048)\n",
            "(20000, 2048) (5000, 2048) (12500, 2048)\n",
            "(20000, 2048) (5000, 2048) (12500, 2048)\n",
            "last: (20000, 6144) (5000, 6144) (12500, 6144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu0gviQaVNOt",
        "colab_type": "text"
      },
      "source": [
        "**训练融合模型**\n",
        "\n",
        "**直接在特征向量上进行训练**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdQ65vLtUmTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "# 打乱数据，模拟现实中的随机效果\n",
        "X_train, y_train = shuffle(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odNHffTnVTnq",
        "colab_type": "code",
        "outputId": "560c6a56-7861-4fe1-9aa3-c667224ea9f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "import keras.utils\n",
        "\n",
        "input_tensor = Input(X_train.shape[1:])\n",
        "x = input_tensor\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "concatenate_model = Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "concatenate_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "concatenate_model.fit(X_train,y_train,batch_size=128, epochs=5,validation_data=(X_valid,y_valid))#validation_split=0.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 4s 176us/step - loss: 0.0430 - acc: 0.9850 - val_loss: 0.0093 - val_acc: 0.9978\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 1s 45us/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0067 - val_acc: 0.9980\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 1s 46us/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0053 - val_acc: 0.9980\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 1s 46us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0051 - val_acc: 0.9982\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 1s 45us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0052 - val_acc: 0.9986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29ee74e860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xXriqfwV8VU",
        "colab_type": "text"
      },
      "source": [
        "**结果预测**\n",
        "\n",
        "**hint：这里我们使用了 clip 函数，这个是一个比赛中的一个非常有效的 Trick（注意，这里强调了比赛，实际项目是没有什么效果的），将我们的输出限制住范围，，如果输出是绝对的，就可以减少损失，提高排名**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7guOsU_mVUiQ",
        "colab_type": "code",
        "outputId": "e6d2ac41-2df2-40de-a680-4bbf57d15a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "import pandas as pd\n",
        "y_pred = concatenate_model.predict(X_test, verbose=1)\n",
        "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
        "\n",
        "df = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "image_size = (224, 224)\n",
        "gen = ImageDataGenerator()\n",
        "test_generator = gen.flow_from_directory(\"/content/test2/\", image_size, shuffle=False, \n",
        "                                         batch_size=16, class_mode=None)\n",
        "\n",
        "for i, fname in enumerate(test_generator.filenames):\n",
        "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
        "    df.set_value(index-1, 'label', y_pred[i])\n",
        "\n",
        "df.to_csv('sample_submission.csv', index=None)\n",
        "\n",
        "print(df.head(20))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500/12500 [==============================] - 1s 69us/step\n",
            "Found 12500 images belonging to 1 classes.\n",
            "    id     label\n",
            "0    1  0.986834\n",
            "1    2  0.995000\n",
            "2    3  0.995000\n",
            "3    4  0.995000\n",
            "4    5  0.005000\n",
            "5    6  0.005000\n",
            "6    7  0.005000\n",
            "7    8  0.005000\n",
            "8    9  0.005000\n",
            "9   10  0.005000\n",
            "10  11  0.005000\n",
            "11  12  0.995000\n",
            "12  13  0.005000\n",
            "13  14  0.005000\n",
            "14  15  0.005000\n",
            "15  16  0.005000\n",
            "16  17  0.995000\n",
            "17  18  0.995000\n",
            "18  19  0.005000\n",
            "19  20  0.005000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyAmdb30XK_8",
        "colab_type": "text"
      },
      "source": [
        "**提交结果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXeoXPM-XIiE",
        "colab_type": "code",
        "outputId": "b6becf00-8ec1-4fbd-a4f8-d79164b43300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f sample_submission.csv -m \"Message\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 306k/306k [00:01<00:00, 238kB/s]\n",
            "Successfully submitted to Dogs vs. Cats Redux: Kernels Edition"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKi05D-d1XUg",
        "colab_type": "text"
      },
      "source": [
        "**最终得分:0.07584**"
      ]
    }
  ]
}